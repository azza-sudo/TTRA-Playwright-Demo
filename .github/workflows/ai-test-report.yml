name: AI Test Report Integration (Demo)

on:
  workflow_dispatch:
  
jobs:
  e2e:
    runs-on: ubuntu-latest
    container:
      image: mcr.microsoft.com/playwright:v1.47.2-noble  # match your Playwright version
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20', cache: 'npm' }

      # expose the installed Playwright version for cache key
      - name: Read Playwright version
        id: pw
        run: echo "PW_VERSION=$(node -p \"require('@playwright/test/package.json').version\")" >> $GITHUB_ENV

      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-pw-${{ env.PW_VERSION }}

      - run: npm ci
      - run: npx playwright install --with-deps
      - run: npx playwright test

      - name: Run Playwright Tests (HTML + JSON to file)
        run: |
          set -o pipefail
          mkdir -p playwright-report
          # Run with both reporters; capture JSON stdout to file reliably.
          # 'tee' writes to the file AND still lets you see JSON in logs.
          npx playwright test --reporter=html,json --output=playwright-report | tee playwright-report/sample_results.json || true
      
          # If for any reason the file is empty or missing, create a minimal JSON so later steps don't fail.
          if [ ! -s playwright-report/sample_results.json ]; then
            echo '{"status":"no-tests-or-failure","suites":[]}' > playwright-report/sample_results.json
          fi
      
          echo "=== Post-run listing ==="
          ls -lah playwright-report
          echo "JSON size:" $(wc -c < playwright-report/sample_results.json)
      
      - name: Upload Playwright Results (JSON)
        uses: actions/upload-artifact@v4
        with:
          name: sample_results
          path: playwright-report/sample_results.json

      # (Optional) If you want to upload the HTML report as well:
      - name: Upload HTML Report
        uses: actions/upload-artifact@v4
        with:
          name: html-report
          path: playwright-report/


  ai-agent:
    needs: run-tests
    runs-on: ubuntu-latest

    steps:
      - name: Checkout AI Agent Repository
        uses: actions/checkout@v4
        with:
          repository: azza-sudo/TestInsight-Agent
          path: testinsight

      - name: Download Test Results
        uses: actions/download-artifact@v4
        with:
          name: sample_results
          path: testinsight

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install AI Agent Dependencies
        working-directory: testinsight
        run: pip install -r requirements.txt

      - name: Run AI Analysis
        working-directory: testinsight
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          echo "Running TestInsight AI Agent..."
          python main.py sample_results.json

      - name: Upload AI Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ai-report
          path: testinsight/ai_report.json
